
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{r}
library('papaja')

df_results <- readRDS('analysis_test/final_results_test.rds')
sim_based_thres <- readRDS('analysis_test/sim_based_thresholds_test.rds')

# Mean within sample range (mwsr)
get_mean_within_sample_range <- function(column){
  range_vec <- vector()
  for (i in seq(from = 1, by = 8, length.out = length(column)/8)){
    range_vec <- append(range_vec, range(column[seq(i, i+7)]))
  }
  return(mean(range_vec))
}

mwsr_savage_dickey_bf <- get_mean_within_sample_range(df_results$savage_dickey_bf)
mwsr_directional_bf <- get_mean_within_sample_range(df_results$directional_bf)
mwsr_p_effect <- get_mean_within_sample_range(df_results$p_effect)

# False positive results
fp_savage_dickey_bf_3 <- sum(df_results$fp_savage_dickey_bf_3)/nrow(df_results)

fp_directional_bf_3 <- sum(df_results$fp_directional_bf_3_pos,
                           df_results$fp_directional_bf_1_3_neg)/nrow(df_results)

fp_directional_bf_10 <- sum(df_results$fp_directional_bf_10_pos,
                            df_results$fp_directional_bf_1_10_neg)/nrow(df_results)

fp_directional_bf_30 <- sum(df_results$fp_directional_bf_30_pos,
                            df_results$fp_directional_bf_1_30_neg)/nrow(df_results)

fp_directional_bf_100 <- sum(df_results$fp_directional_bf_100_pos,
                             df_results$fp_directional_bf_1_100_neg)/nrow(df_results)

fp_p_effect_95 <- sum(df_results$fp_p_effect_95_pos,
                      df_results$fp_p_effect_05_neg)/nrow(df_results)

fp_p_effect_975 <- sum(df_results$fp_p_effect_975_pos,
                       df_results$fp_p_effect_025_neg)/nrow(df_results)

fp_p_effect_99 <- sum(df_results$fp_p_effect_99_pos,
                      df_results$fp_p_effect_01_neg)/nrow(df_results)

fp_hdi_80 <- sum(df_results$fp_hdi_80_pos,
                 df_results$fp_hdi_80_neg)/nrow(df_results)

fp_hdi_90 <- sum(df_results$fp_hdi_90_pos,
                 df_results$fp_hdi_90_neg)/nrow(df_results)

fp_hdi_95 <- sum(df_results$fp_hdi_95_pos,
                 df_results$fp_hdi_95_neg)/nrow(df_results)

fp_hdi_99 <- sum(df_results$fp_hdi_99_pos,
                 df_results$fp_hdi_99_neg)/nrow(df_results)


# Overlap of false positive results (ofp)
# Check if n_fp_per_method is the same for every method
n_fp_per_method <- sum(df_results$fp_savage_dickey_bf_sim)
n_fp2 <- sum(df_results$fp_directional_bf_sim_pos, df_results$fp_directional_bf_sim_neg)
n_fp3 <- sum(df_results$fp_p_effect_sim_pos, df_results$fp_p_effect_sim_neg)
n_fp4 <- sum(df_results$fp_hdi_sim_pos, df_results$fp_hdi_sim_neg)

ofp_savage_dickey_bf_directional_bf <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                             df_results$fp_directional_bf_sim_pos == 1 |
                                             df_results$fp_directional_bf_sim_neg == 1) / n_fp_per_method

ofp_savage_dickey_bf_hdi <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                  df_results$fp_hdi_sim_pos == 1 &
                                  df_results$fp_hdi_sim_neg == 1) / n_fp_per_method

ofp_savage_dickey_bf_p_effect <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                       df_results$fp_p_effect_sim_pos == 1 &
                                       df_results$fp_p_effect_sim_neg == 1) / n_fp_per_method

ofp_directional_bf_hdi <- sum(df_results$fp_directional_bf_sim_pos == 1 &
                                df_results$fp_hdi_sim_pos == 1,
                              df_results$fp_directional_bf_sim_neg == 1 &
                                df_results$fp_hdi_sim_neg == 1) / n_fp_per_method

ofp_directional_bf_p_effect <- sum(df_results$fp_directional_bf_sim_pos == 1 &
                                     df_results$fp_p_effect_sim_pos == 1,
                                   df_results$fp_directional_bf_sim_neg == 1 &
                                     df_results$fp_p_effect_sim_neg == 1) / n_fp_per_method

ofp_hdi_p_effect <- sum(df_results$fp_hdi_sim_pos == 1 &
                          df_results$fp_p_effect_sim_pos == 1,
                        df_results$fp_hdi_sim_neg == 1 &
                          df_results$fp_p_effect_sim_neg == 1) / n_fp_per_method


# Prior sensitivity (ps; proportion of samples in which a method came to diverging results)
get_ps_null_method <- function(column){
  counter <- 0
  for (i in seq(from = 1, by = 8, length.out = length(column)/8)){
    if (all(column[i] == column[seq(i, i+7)]) == FALSE){
      counter <- counter + 1
    }
  }
  proportion <- counter/(length(column)/8)
  return(proportion)
}


get_ps_directional_method <- function(column_pos, column_neg){
  counter <- 0
  for (i in seq(from = 1, by = 8, length.out = length(column_pos)/8)){
    if ((all(column_pos[i] == column_pos[seq(i, i+7)]) == TRUE) &
        (all(column_neg[i] == column_neg[seq(i, i+7)]) == TRUE)){
      counter <- counter + 1
    }
  }
  proportion <- 1 - counter/(length(column_pos)/8)
  return(proportion)
}


ps_savage_dickey_bf_sim <- 
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim)

ps_savage_dickey_bf_sim_0_2 <-
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.2])

ps_savage_dickey_bf_sim_0_51 <- 
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.51])

ps_savage_dickey_bf_sim_0_81 <- 
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.81])


ps_directional_bf_sim <- 
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos,
                            df_results$fp_directional_bf_sim_neg)

ps_directional_bf_sim_0_2 <- 
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos[df_results$s_log_k_sd == 0.2],
                            df_results$fp_directional_bf_sim_neg[df_results$s_log_k_sd == 0.2])

ps_directional_bf_sim_0_51 <-
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos[df_results$s_log_k_sd == 0.51],
                            df_results$fp_directional_bf_sim_neg[df_results$s_log_k_sd == 0.51])

ps_directional_bf_sim_0_81 <-
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos[df_results$s_log_k_sd == 0.81],
                            df_results$fp_directional_bf_sim_neg[df_results$s_log_k_sd == 0.81])


ps_hdi_sim <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos,
                            df_results$fp_hdi_sim_neg)

ps_hdi_sim_0_2 <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos[df_results$s_log_k_sd == 0.2],
                            df_results$fp_hdi_sim_neg[df_results$s_log_k_sd == 0.2])

ps_hdi_sim_0_51 <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos[df_results$s_log_k_sd == 0.51],
                            df_results$fp_hdi_sim_neg[df_results$s_log_k_sd == 0.51])

ps_hdi_sim_0_81 <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos[df_results$s_log_k_sd == 0.81],
                            df_results$fp_hdi_sim_neg[df_results$s_log_k_sd == 0.81])


ps_p_effect_sim <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos,
                            df_results$fp_p_effect_sim_neg)

ps_p_effect_sim_0_2 <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos[df_results$s_log_k_sd == 0.2],
                            df_results$fp_p_effect_sim_neg[df_results$s_log_k_sd == 0.2])

ps_p_effect_sim_0_51 <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos[df_results$s_log_k_sd == 0.51],
                            df_results$fp_p_effect_sim_neg[df_results$s_log_k_sd == 0.51])

ps_p_effect_sim_0_81 <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos[df_results$s_log_k_sd == 0.81],
                            df_results$fp_p_effect_sim_neg[df_results$s_log_k_sd == 0.81])


remove_leading_zero <- function(value){
  value <- gsub("0\\.", ".", value)
  return(value)
}

```

`\section{Results}`  
Across all models, Savage-Dickey BFs ranged from `r round(min(df_results$savage_dickey_bf),2)` to `r round(max(df_results$savage_dickey_bf),2)` (`\textit{M}` = `r round(mean(df_results$savage_dickey_bf),2)`, `\textit{SD}` = `r round(sd(df_results$savage_dickey_bf),2)`), dBFs ranged from `r round(min(df_results$directional_bf),2)` to `r round(max(df_results$directional_bf),2)` (`\textit{M}` = `r round(mean(df_results$directional_bf),2)`, `\textit{SD}` = `r round(sd(df_results$directional_bf),2)`) and P(effect > 0) ranged from `r remove_leading_zero(round(min(df_results$p_effect),2))` to `r remove_leading_zero(round(max(df_results$p_effect),2))` (`\textit{M}` = `r remove_leading_zero(round(mean(df_results$p_effect),2))`, `\textit{SD}` = `r remove_leading_zero(round(sd(df_results$p_effect),2))`). See Figure `ref{fig:values}` for the distributions of Savage-Dickey BFs, dBFs and P(effect > 0) proportions.`\\`

```
\begin{figure} [H]
    \centering
    \caption{Distributions of Savage-Dickey BFs, dBFs and P(effect > 0) proportions}
    \label{fig:values}
    \includegraphics[width=1\linewidth]{figures/multiplot_values.pdf}
    \caption*{Note. \textnormal{Distribution of Savage-Dickey BFs (A), dBFs (B), and and P(effect > 0) proportions (C). Solid lines represent mean values.}}
\end{figure}
```
<br>
`\subsection{False positive results}`  
With a decision threshold of 3, `r round(fp_savage_dickey_bf_3 * 100, 2)``\%` of Savage-Dickey BFs were false positive. With a decision threshold of 1/3 for a negative and 3 for a positive effect, `r round(fp_directional_bf_3 * 100, 2)``\%` of dBFs were false positive. With 1/10 and 10 as directional decision thresholds, `r round(fp_directional_bf_10 * 100, 2)``\%` of dBFs were false positive, with 1/30 and 30, `r round(fp_directional_bf_30 * 100, 2)``\%` and with 1/100 and 100, `r round(fp_directional_bf_100 * 100, 2)``\%`. With a 80`\%` HDI, `r round(fp_hdi_80 * 100, 2)``\%` of decisions were false positive, with a 90`\%` HDI, `r round(fp_hdi_90 * 100, 2)``\%`, with a 95`\%` HDI, `r round(fp_hdi_95 * 100, 2)``\%` and with a 99`\%` HDI, `r round(fp_hdi_99 * 100, 2)``\%`. With P(effect > 0) > .95 for a positive and P(effect > 0) < .05 for negative effect, `r round(fp_p_effect_95 * 100, 2)``\%` of P(effect > 0) proportions were false positive. With > .975 and < .025 as directional thresholds, `r round(fp_p_effect_975 * 100, 2)``\%` of P(effect > 0) proportions were false positive and with > .99 and < .01, `r round(fp_p_effect_99 * 100, 2)``\%`. See Figure `\ref{fig:fig_fp}` for the proportions of false positive results per prior and population effect `\textit{SD}`.`\\`

```
\begin{figure} [H]
    \centering
    \caption{Proportions of false positive results with conventional decision thresholds}
    \label{fig:fig_fp}
    \includegraphics[width=1\linewidth]{figures/multiplot_fp.pdf}
    \caption*{Note. \textnormal{Dashed lines indicate a proportion of 5\% false positive results.}}
\end{figure}
```
<br>
`\subsection{Simulation-based decision thresholds}`  
With a decision threshold of `r round(sim_based_thres$savage_dickey_bf[1],2)`, 5`\%` of Savage Dickey BFs were false positive. The dBF produced 5`\%` false positive results, with a decision threshold of `r round(sim_based_thres$directional_bf_upper[1],2)` for a positive and `r round(sim_based_thres$directional_bf_lower[1],2)` for a negative effect. A decision rule of P(effect > 0) > `r remove_leading_zero(round(sim_based_thres$p_effect_upper[1],2))` for a positive and P(effect > 0) < `r remove_leading_zero(round(sim_based_thres$p_effect_lower[1],2))` for a negative effect resulted in 5`\%` false positives. The HDI against zero decision rule produced 5`\%` false positive results with a `r round(sim_based_thres$hdi[1]*100,2)``\%` HDI. Simulation-based decision thresholds for single and multiple tests are shown in Figure `ref{fig:thresholds}`.`\\`

```
\begin{figure} [H]
    \centering
    \caption{Simulation-based decision thresholds for single and multiple tests}
    \label{fig:thresholds}
    \includegraphics[width=1\linewidth]{figures/multiplot_thresholds.pdf}
\end{figure}
```
<br>
`\subsubsection{Overlap of false positive results}`  
With simulation-based decision thresholds, `r round(ofp_savage_dickey_bf_directional_bf*100,2)``\%` of false positive Savage-Dickey BFs overlapped with false positive dBFs, `r round(ofp_savage_dickey_bf_hdi*100,2)``\%` overlapped with false positive HDI decisions and `r round(ofp_savage_dickey_bf_p_effect*100,2)``\%` overlapped with false positive P(effect > 0) proportions. `r round(ofp_directional_bf_hdi*100,2)``\%` of false positive dBFs overlapped with false positive HDI decisions and `r round(ofp_directional_bf_p_effect*100,2)``\%` overlapped with false positive P(effect > 0) proportions. `r round(ofp_hdi_p_effect*100,2)``\%` of false positive HDI decisions overlapped with false positive P(effect > 0) proportions.`\\`

`\subsubsection{Prior sensitivity}`  
Within samples, the mean range of Savage-Dickey BFs was `r round(mwsr_savage_dickey_bf,2)`, the mean range of dBFs was `r round(mwsr_directional_bf,2)`, and the mean range of P(effect > 0) proportions was `r round(mwsr_p_effect,2)`.  
`\\`  
With simulation-based decision thresholds, the Savage-Dickey BF came to diverging results due to different priors within `r round(ps_savage_dickey_bf_sim * 100, 2)``\%` of all samples. The dBF produced inconsistent results within `r round(ps_directional_bf_sim * 100, 2)``\%` of all samples. The HDI against zero decision rule came to different results within `r round(ps_hdi_sim * 100, 2)``\%` of all samples and P(effect > 0) came to diverging results within `r round(ps_p_effect_sim * 100, 2)``\%` of all samples. See Table `\ref{tab:prior_sensitivity}` for the prior sensitivities per population effect `\textbf{SD}`.`\\`

```
\begin{table}[H]
    \caption{Prior sensitivity of each inference method per population effect SD}
    \label{tab:prior_sensitivity}
    \begin{tabularx}{\textwidth}{lXXX}
    \midrule
    \multicolumn{1}{c}{Inference method} & \multicolumn{3}{c}{Prior sensitivity per effect \textit{SD}}\\
    \cmidrule{2-4}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{0.2} & \multicolumn{1}{c}{0.51} & \multicolumn{1}{c}{0.81}\\
    \midrule
    Savage-Dickey $BF_{10}$ & \centering `r remove_leading_zero(ps_savage_dickey_bf_sim_0_2)` & \centering `r remove_leading_zero(ps_savage_dickey_bf_sim_0_51)` & \centering `r remove_leading_zero(ps_savage_dickey_bf_sim_0_81)`\arraybackslash\\
    $dBF_{+-}$ & \centering `r remove_leading_zero(ps_directional_bf_sim_0_2)` & \centering `r remove_leading_zero(ps_directional_bf_sim_0_51)` & \centering `r remove_leading_zero(ps_directional_bf_sim_0_81)`\arraybackslash\\
    95\% HDI & \centering `r remove_leading_zero(ps_hdi_sim_0_2)` & \centering `r remove_leading_zero(ps_hdi_sim_0_51)` & \centering `r remove_leading_zero(ps_hdi_sim_0_81)`\arraybackslash\\
    P(effect > 0) & \centering `r remove_leading_zero(ps_p_effect_sim_0_2)` & \centering `r remove_leading_zero(ps_p_effect_sim_0_51)` & \centering `r remove_leading_zero(ps_p_effect_sim_0_81)`\arraybackslash\\
    \midrule
    \end{tabularx}
\end{table}
```
<br>
