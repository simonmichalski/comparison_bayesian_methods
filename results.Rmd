
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

```{r}
#library('papaja')
library("dplyr")

df_results <- readRDS(file.path("final_results", "final_results.rds"))
sim_based_thres <- readRDS(file.path("final_results", "sim_based_thresholds.rds"))
df_recovery <- readRDS(file.path("final_results", "recovery.rds"))

# Correlation true-estimated subject-level parameters
data_cor_s_log_k <- summarize(group_by(df_recovery, s_log_k_sd, prior_sd, sample), 
                              correlation = cor(true_s_log_k, median_s_log_k))
mean_cor_s_log_k_overall <- mean(data_cor_s_log_k$correlation)
iqr_cor_s_log_k_overall <- IQR(data_cor_s_log_k$correlation)
mean_cor_s_log_k_0_2 <- mean(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.2])
iqr_cor_s_log_k_0_2 <- IQR(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.2])
mean_cor_s_log_k_0_51 <- mean(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.51])
iqr_cor_s_log_k_0_51 <- IQR(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.51])
mean_cor_s_log_k_0_81 <- mean(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.81])
iqr_cor_s_log_k_0_81 <- IQR(data_cor_s_log_k$correlation[data_cor_s_log_k$s_log_k_sd == 0.81])

data_cor_log_k <- summarize(group_by(df_recovery, s_log_k_sd, prior_sd, sample), 
                            correlation = cor(true_log_k, median_log_k))
mean_cor_log_k_overall <- mean(data_cor_log_k$correlation)
iqr_cor_log_k_overall <- IQR(data_cor_log_k$correlation)

# Subject-level parameter shrinkage
sd_estimates_s_log_k <- aggregate(df_recovery, median_s_log_k ~ prior_sd + s_log_k_sd + sample, sd)
sd_true_s_log_k <- aggregate(df_recovery, true_s_log_k ~ prior_sd + s_log_k_sd + sample, sd)
data_shrinkage_s_log_k <- merge(sd_estimates_s_log_k, sd_true_s_log_k, by = c("s_log_k_sd", "prior_sd", "sample"))
data_shrinkage_s_log_k$sd_reduction <- (data_shrinkage_s_log_k$true_s_log_k - data_shrinkage_s_log_k$median_s_log_k) / data_shrinkage_s_log_k$true_s_log_k
mean_shrinkage_overall <- mean(data_shrinkage_s_log_k$sd_reduction)
sd_shrinkage_overall <- sd(data_shrinkage_s_log_k$sd_reduction)
mean_shrinkage_0_2 <- mean(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.2, "sd_reduction"])
sd_shrinkage_0_2 <- sd(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.2, "sd_reduction"])
mean_shrinkage_0_51 <-mean(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.51, "sd_reduction"])
sd_shrinkage_0_51 <-sd(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.51, "sd_reduction"])
mean_shrinkage_0_81 <-mean(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.81, "sd_reduction"])
sd_shrinkage_0_81 <-sd(data_shrinkage_s_log_k[data_shrinkage_s_log_k$s_log_k_sd == 0.81, "sd_reduction"])
mean_sd_true_0_2 <- mean(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
sd_sd_true_0_2 <- sd(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
mean_sd_true_0_51 <- mean(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
sd_sd_true_0_51 <- sd(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
mean_sd_true_0_81 <- mean(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])
sd_sd_true_0_81 <- sd(sd_true_s_log_k[sd_true_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])
mean_sd_estimates_0_2 <- mean(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.2, "median_s_log_k"])
sd_sd_estimates_0_2 <- sd(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.2, "median_s_log_k"])
mean_sd_estimates_0_51 <- mean(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.51, "median_s_log_k"])
sd_sd_estimates_0_51 <- sd(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.51, "median_s_log_k"])
mean_sd_estimates_0_81 <- mean(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.81, "median_s_log_k"])
sd_sd_estimates_0_81 <- sd(sd_estimates_s_log_k[sd_estimates_s_log_k$s_log_k_sd == 0.81, "median_s_log_k"])

sd_estimates_log_k <- aggregate(df_recovery, median_log_k ~ prior_sd + s_log_k_sd + sample, sd)
sd_true_log_k <- aggregate(df_recovery, true_log_k ~ prior_sd + s_log_k_sd + sample, sd)
data_shrinkage_log_k <- merge(sd_estimates_log_k, sd_true_log_k, by = c("s_log_k_sd", "prior_sd", "sample"))
data_shrinkage_log_k$sd_reduction <- (data_shrinkage_log_k$true_log_k - data_shrinkage_log_k$median_log_k) / data_shrinkage_log_k$true_log_k
mean_shrinkage_overall_log_k <- mean(data_shrinkage_log_k$sd_reduction)
sd_shrinkage_overall_log_k <- sd(data_shrinkage_log_k$sd_reduction)
mean_sd_true_overall_log_k <- mean(sd_true_log_k$true_log_k)
sd_sd_true_overall_log_k <- sd(sd_true_log_k$true_log_k)
mean_sd_estimates_overall_log_k <- mean(sd_estimates_log_k$median_log_k)
sd_sd_estimates_overall_log_k <- sd(sd_estimates_log_k$median_log_k)

# Recovery group-level mean
true_means_s_log_k <- aggregate(df_recovery, true_s_log_k ~ prior_sd + s_log_k_sd + sample, mean)
mean_true_group_level_mean_overall <- mean(true_means_s_log_k$true_s_log_k)
sd_true_group_level_mean_overall <- sd(true_means_s_log_k$true_s_log_k)
mean_true_group_level_mean_0_2 <- mean(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
sd_true_group_level_mean_0_2 <- sd(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.2, "true_s_log_k"])
mean_true_group_level_mean_0_51 <- mean(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
sd_true_group_level_mean_0_51 <- sd(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.51, "true_s_log_k"])
mean_true_group_level_mean_0_81 <- mean(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])
sd_true_group_level_mean_0_81 <- sd(true_means_s_log_k[true_means_s_log_k$s_log_k_sd == 0.81, "true_s_log_k"])

true_means_log_k <- aggregate(df_recovery, true_log_k ~ prior_sd + s_log_k_sd + sample, mean)
mean_true_group_level_mean_log_k <- mean(true_means_log_k$true_log_k)
sd_true_group_level_mean_log_k <- sd(true_means_log_k$true_log_k)

mean_group_level_mean_overall <- mean(df_results$median_mu_s_log_k)
sd_group_level_mean_overall <- sd(df_results$median_mu_s_log_k)
mean_group_level_mean_0_2 <- mean(df_results[df_results$s_log_k_sd == 0.2, "median_mu_s_log_k"])
sd_group_level_mean_0_2 <- sd(df_results[df_results$s_log_k_sd == 0.2, "median_mu_s_log_k"])
mean_group_level_mean_0_51 <- mean(df_results[df_results$s_log_k_sd == 0.51, "median_mu_s_log_k"])
sd_group_level_mean_0_51 <- sd(df_results[df_results$s_log_k_sd == 0.51, "median_mu_s_log_k"])
mean_group_level_mean_0_81 <- mean(df_results[df_results$s_log_k_sd == 0.81, "median_mu_s_log_k"])
sd_group_level_mean_0_81 <- sd(df_results[df_results$s_log_k_sd == 0.81, "median_mu_s_log_k"])

mean_group_level_mean_log_k <- mean(df_results$median_mu_log_k)
sd_group_level_mean_log_k <- sd(df_results$median_mu_log_k)

# Recovery group-level SD
mean_group_level_sd_0_2 <- mean(df_results[df_results$s_log_k_sd == 0.2, "median_sd_s_log_k"])
sd_group_level_sd_0_2 <- sd(df_results[df_results$s_log_k_sd == 0.2, "median_sd_s_log_k"])
mean_group_level_sd_0_51 <- mean(df_results[df_results$s_log_k_sd == 0.51, "median_sd_s_log_k"])
sd_group_level_sd_0_51 <- sd(df_results[df_results$s_log_k_sd == 0.51, "median_sd_s_log_k"])
mean_group_level_sd_0_81 <- mean(df_results[df_results$s_log_k_sd == 0.81, "median_sd_s_log_k"])
sd_group_level_sd_0_81 <- sd(df_results[df_results$s_log_k_sd == 0.81, "median_sd_s_log_k"])

mean_group_level_sd_log_k <- mean(df_results$median_sd_log_k)
sd_group_level_sd_log_k <- sd(df_results$median_sd_log_k)

# Mean within sample range (mwsr)
get_mean_within_sample_range <- function(column){
  range_vec <- vector()
  for (i in seq(from = 1, by = 8, length.out = length(column)/8)){
    range_vec <- append(range_vec, range(column[seq(i, i+7)]))
  }
  return(mean(range_vec))
}

mwsr_savage_dickey_bf <- get_mean_within_sample_range(df_results$savage_dickey_bf)
mwsr_directional_bf <- get_mean_within_sample_range(df_results$directional_bf)
mwsr_p_effect <- get_mean_within_sample_range(df_results$p_effect)

# False positive results
fp_savage_dickey_bf_3 <- sum(df_results$fp_savage_dickey_bf_3)/nrow(df_results)

fp_directional_bf_3 <- sum(df_results$fp_directional_bf_3_pos,
                           df_results$fp_directional_bf_1_3_neg)/nrow(df_results)

fp_directional_bf_10 <- sum(df_results$fp_directional_bf_10_pos,
                            df_results$fp_directional_bf_1_10_neg)/nrow(df_results)

fp_directional_bf_30 <- sum(df_results$fp_directional_bf_30_pos,
                            df_results$fp_directional_bf_1_30_neg)/nrow(df_results)

fp_directional_bf_100 <- sum(df_results$fp_directional_bf_100_pos,
                             df_results$fp_directional_bf_1_100_neg)/nrow(df_results)

fp_p_effect_95 <- sum(df_results$fp_p_effect_95_pos,
                      df_results$fp_p_effect_05_neg)/nrow(df_results)

fp_p_effect_975 <- sum(df_results$fp_p_effect_975_pos,
                       df_results$fp_p_effect_025_neg)/nrow(df_results)

fp_p_effect_99 <- sum(df_results$fp_p_effect_99_pos,
                      df_results$fp_p_effect_01_neg)/nrow(df_results)

fp_hdi_80 <- sum(df_results$fp_hdi_80_pos,
                 df_results$fp_hdi_80_neg)/nrow(df_results)

fp_hdi_90 <- sum(df_results$fp_hdi_90_pos,
                 df_results$fp_hdi_90_neg)/nrow(df_results)

fp_hdi_95 <- sum(df_results$fp_hdi_95_pos,
                 df_results$fp_hdi_95_neg)/nrow(df_results)

fp_hdi_99 <- sum(df_results$fp_hdi_99_pos,
                 df_results$fp_hdi_99_neg)/nrow(df_results)


# Overlap of false positive results (ofp)
# Number of false positives per method
n_fp_savage_dickey_bf <- sum(df_results$fp_savage_dickey_bf_sim)
n_fp_directional_bf <- sum(df_results$fp_directional_bf_sim_pos, df_results$fp_directional_bf_sim_neg)
n_fp_p_effect <- sum(df_results$fp_p_effect_sim_pos, df_results$fp_p_effect_sim_neg)
n_fp_hdi <- sum(df_results$fp_hdi_sim_pos, df_results$fp_hdi_sim_neg)

ofp_savage_dickey_bf_directional_bf <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                             df_results$fp_directional_bf_sim_pos == 1 |
                                             df_results$fp_directional_bf_sim_neg == 1) / n_fp_savage_dickey_bf

ofp_savage_dickey_bf_hdi <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                  df_results$fp_hdi_sim_pos == 1 |
                                  df_results$fp_hdi_sim_neg == 1) / n_fp_savage_dickey_bf

ofp_savage_dickey_bf_p_effect <- sum(df_results$fp_savage_dickey_bf_sim == 1 &
                                       df_results$fp_p_effect_sim_pos == 1 |
                                       df_results$fp_p_effect_sim_neg == 1) / n_fp_savage_dickey_bf

ofp_directional_bf_hdi <- sum(df_results$fp_directional_bf_sim_pos == 1 &
                                df_results$fp_hdi_sim_pos == 1,
                              df_results$fp_directional_bf_sim_neg == 1 &
                                df_results$fp_hdi_sim_neg == 1) / n_fp_directional_bf

ofp_directional_bf_p_effect <- sum(df_results$fp_directional_bf_sim_pos == 1 &
                                     df_results$fp_p_effect_sim_pos == 1,
                                   df_results$fp_directional_bf_sim_neg == 1 &
                                     df_results$fp_p_effect_sim_neg == 1) / n_fp_directional_bf

ofp_hdi_p_effect <- sum(df_results$fp_hdi_sim_pos == 1 &
                          df_results$fp_p_effect_sim_pos == 1,
                        df_results$fp_hdi_sim_neg == 1 &
                          df_results$fp_p_effect_sim_neg == 1) / n_fp_hdi


# Prior sensitivity (ps; proportion of samples in which a method came to diverging results)
get_ps_null_method <- function(column){
  counter <- 0
  for (i in seq(from = 1, by = 8, length.out = length(column)/8)){
    if (all(column[i] == column[seq(i, i+7)]) == FALSE){
      counter <- counter + 1
    }
  }
  proportion <- counter/(length(column)/8)
  return(proportion)
}


get_ps_directional_method <- function(column_pos, column_neg){
  counter <- 0
  for (i in seq(from = 1, by = 8, length.out = length(column_pos)/8)){
    if ((all(column_pos[i] == column_pos[seq(i, i+7)]) == TRUE) &
        (all(column_neg[i] == column_neg[seq(i, i+7)]) == TRUE)){
      counter <- counter + 1
    }
  }
  proportion <- 1 - counter/(length(column_pos)/8)
  return(proportion)
}


ps_savage_dickey_bf_sim <- 
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim)

ps_savage_dickey_bf_sim_0_2 <-
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.2])

ps_savage_dickey_bf_sim_0_51 <- 
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.51])

ps_savage_dickey_bf_sim_0_81 <- 
  get_ps_null_method(df_results$fp_savage_dickey_bf_sim[df_results$s_log_k_sd == 0.81])


ps_directional_bf_sim <- 
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos,
                            df_results$fp_directional_bf_sim_neg)

ps_directional_bf_sim_0_2 <- 
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos[df_results$s_log_k_sd == 0.2],
                            df_results$fp_directional_bf_sim_neg[df_results$s_log_k_sd == 0.2])

ps_directional_bf_sim_0_51 <-
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos[df_results$s_log_k_sd == 0.51],
                            df_results$fp_directional_bf_sim_neg[df_results$s_log_k_sd == 0.51])

ps_directional_bf_sim_0_81 <-
  get_ps_directional_method(df_results$fp_directional_bf_sim_pos[df_results$s_log_k_sd == 0.81],
                            df_results$fp_directional_bf_sim_neg[df_results$s_log_k_sd == 0.81])


ps_hdi_sim <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos,
                            df_results$fp_hdi_sim_neg)

ps_hdi_sim_0_2 <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos[df_results$s_log_k_sd == 0.2],
                            df_results$fp_hdi_sim_neg[df_results$s_log_k_sd == 0.2])

ps_hdi_sim_0_51 <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos[df_results$s_log_k_sd == 0.51],
                            df_results$fp_hdi_sim_neg[df_results$s_log_k_sd == 0.51])

ps_hdi_sim_0_81 <- 
  get_ps_directional_method(df_results$fp_hdi_sim_pos[df_results$s_log_k_sd == 0.81],
                            df_results$fp_hdi_sim_neg[df_results$s_log_k_sd == 0.81])


ps_p_effect_sim <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos,
                            df_results$fp_p_effect_sim_neg)

ps_p_effect_sim_0_2 <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos[df_results$s_log_k_sd == 0.2],
                            df_results$fp_p_effect_sim_neg[df_results$s_log_k_sd == 0.2])

ps_p_effect_sim_0_51 <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos[df_results$s_log_k_sd == 0.51],
                            df_results$fp_p_effect_sim_neg[df_results$s_log_k_sd == 0.51])

ps_p_effect_sim_0_81 <- 
  get_ps_directional_method(df_results$fp_p_effect_sim_pos[df_results$s_log_k_sd == 0.81],
                            df_results$fp_p_effect_sim_neg[df_results$s_log_k_sd == 0.81])


remove_leading_zero <- function(value){
  value <- gsub("0\\.", ".", value)
  return(value)
}

```

`\section{Results}`
`\subsection{Recovery of subject-level parameters}`
The mean correlation between true and estimated subject-level s`\textsubscript{log(\textit{k})}` parameters was `\textit{r}` = `r remove_leading_zero(round(mean_cor_s_log_k_0_2,2))` (`\textit{IQR}` = `r remove_leading_zero(round(iqr_cor_s_log_k_0_2,2))`) within models fitted to samples of the small population effect standard deviation, `\textit{r}` = `r remove_leading_zero(round(mean_cor_s_log_k_0_51,2))` (`\textit{IQR}` = `r remove_leading_zero(round(iqr_cor_s_log_k_0_51,2))`) within models fitted to samples from the medium population effect standard deviation, and `\textit{r}` = `r remove_leading_zero(round(mean_cor_s_log_k_0_81,2))` (`\textit{IQR}` = `r remove_leading_zero(round(iqr_cor_s_log_k_0_81,2))`) within models fitted to samples from the large population effect standard deviation. The mean correlation within models over all population effect standard deviations was `\textit{r}` = `r remove_leading_zero(round(mean_cor_s_log_k_overall,2))` (`\textit{IQR}` = `r remove_leading_zero(round(iqr_cor_s_log_k_overall,2))`). The mean correlation within models between true and estimated subject-level log(`\textit{k}`) parameters was `\textit{r}` = `r remove_leading_zero(round(mean_cor_log_k_overall,2))` (`\textit{IQR}` = `r remove_leading_zero(round(iqr_cor_log_k_overall,2))`).
`\\`
Since hierarchical Bayesian models perform partial pooling, subject-level parameter shrinkage was computed for each model by dividing the difference between the standard deviation of the true subject-level parameters and the standard deviation of the estimated subject-level parameters with the standard deviation of the true subject-level parameters `\autocite{kruschke_doing_2015}`. On average, the true subject-level standard deviation of s`\textsubscript{log(\textit{k})}` parameters was reduced by `r round(mean_shrinkage_overall * 100, 2)``\%` (`\textit{SD}` = `r round(sd_shrinkage_overall * 100, 2)`) within models. Descriptively, shrinkage of subject-level parameters was stronger, the lower the standard deviation of the sampling distribution was (Table `\ref{tab:shrinkage}`), but constant across all variations of the group-level mean prior of s`\textsubscript{log(\textit{k})}` (Figure Supplement).

```
\begin{table}[H]
    \caption{Shrinkage of subject-level parameters within models}
    \label{tab:shrinkage}
    \begin{tabularx}{\textwidth}{lXXXXXX}
    \midrule
    \multicolumn{1}{c}{Sampling distribution} & \multicolumn{2}{c}{\textit{SD} true parameters} & \multicolumn{2}{c}{\textit{SD} estimates} & \multicolumn{2}{c}{\textit{SD} reduction (\%)}\\
    \cmidrule{2-7}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{\textit{M}} & \multicolumn{1}{c}{\textit{SD}} & \multicolumn{1}{c}{\textit{M}} & \multicolumn{1}{c}{\textit{SD}} & \multicolumn{1}{c}{\textit{M}} & \multicolumn{1}{c}{\textit{SD}}\\
    \midrule
    s\textsubscript{log(\textit{k})} $\sim \mathcal{N}$(0,0.2) & \centering `r round(mean_sd_true_0_2,2)` & \centering `r round(sd_sd_true_0_2,2)` & \centering `r round(mean_sd_estimates_0_2,2)` & \centering `r round(sd_sd_estimates_0_2,2)` & \centering `r round(mean_shrinkage_0_2 * 100, 2)` & \centering `r  round(sd_shrinkage_0_2 * 100,2)`\arraybackslash\\
    s\textsubscript{log(\textit{k})} $\sim \mathcal{N}$(0,0.51) & \centering `r round(mean_sd_true_0_51,2)` & \centering `r round(sd_sd_true_0_51,2)` & \centering `r round(mean_sd_estimates_0_51,2)` & \centering `r round(sd_sd_estimates_0_51,2)` & \centering `r round(mean_shrinkage_0_51 * 100, 2)` & \centering `r round(sd_shrinkage_0_51 * 100,2)`\arraybackslash\\
    s\textsubscript{log(\textit{k})} $\sim \mathcal{N}$(0,0.81) & \centering `r round(mean_sd_true_0_81,2)` & \centering `r round(sd_sd_true_0_81,2)` & \centering `r round(mean_sd_estimates_0_81,2)` & \centering `r  round(sd_sd_estimates_0_81,2)` & \centering `r round(mean_shrinkage_0_81 * 100, 2)` & \centering `r round(sd_shrinkage_0_81 * 100,2)`\arraybackslash\\
    log(\textit{k}) $\sim \mathcal{N}$(-4.79,1.02) & \centering `r round(mean_sd_true_overall_log_k,2)` & \centering `r round(sd_sd_true_overall_log_k,2)` & \centering `r round(mean_sd_estimates_overall_log_k,2)` & \centering `r  round(sd_sd_estimates_overall_log_k,2)` & \centering `r round(mean_shrinkage_overall_log_k * 100, 2)` & \centering `r  round(sd_shrinkage_overall_log_k * 100,2)`\arraybackslash\\
    \midrule
    \end{tabularx}
\end{table}
```

`\subsection{Recovery of group-level parameters}`
The mean true group-level mean of s`\textsubscript{log(\textit{k})}` parameters was `r round(mean_true_group_level_mean_0_2,2)` (`\textit{SD}` = `r round(sd_true_group_level_mean_0_2,2)`) within samples from the small population effect standard deviation, `r round(mean_true_group_level_mean_0_51,2)` (`\textit{SD}` = `r round(sd_true_group_level_mean_0_51,2)`) within samples from the medium population effect standard deviation, and `r round(mean_true_group_level_mean_0_81,2)` (`\textit{SD}` = `r round(sd_true_group_level_mean_0_81,2)`) within samples from the small population effect standard deviation. The mean true group-level mean of log(`\textit{k}`) parameters was `r round(mean_true_group_level_mean_log_k,2)` (`\textit{SD}` = `r round(sd_true_group_level_mean_log_k,2)`). The mean estimate of the group-level mean of s`\textsubscript{log(\textit{k})}` was `r round(mean_group_level_mean_0_2, 2)` (`\textit{SD}` = `r round(sd_group_level_mean_0_2, 2)`) within models fitted to samples from the small population effect standard deviation, `r round(mean_group_level_mean_0_51, 2)` (`\textit{SD}` = `r round(sd_group_level_mean_0_51, 2)`) within models fitted to samples from the medium population effect standard deviation, and `r round(mean_group_level_mean_0_81, 2)` (`\textit{SD}` = `r round(sd_group_level_mean_0_81, 2)`) within models fitted to samples from the large population effect standard deviation. Mean absolute estimates of the group-level mean of s`\textsubscript{log(\textit{k})}` per population effect and prior standard deviation are depicted in Figure `\ref{fig:recovery}`. Descriptively, mean absolute estimates of the group-level mean were constant with wider priors, but decreased with decreasing prior width. The mean estimate of the group-level mean of log(`\textit{k}`) was `r round(mean_group_level_mean_log_k, 2)` (`\textit{SD}` = `r round(sd_group_level_mean_log_k, 2)`).
`\\`
The mean estimate of the group-level standard deviation of s`\textsubscript{log(\textit{k})}` was `r round(mean_group_level_sd_0_2, 2)` (`\textit{SD}` = `r round(sd_group_level_sd_0_2, 2)`) within models fitted to samples from the small population effect standard deviation, `r round(mean_group_level_sd_0_51, 2)` (`\textit{SD}` = `r round(sd_group_level_sd_0_51, 2)`) within models fitted to samples from the medium population effect standard deviation, and `r round(mean_group_level_sd_0_81, 2)` (`\textit{SD}` = `r round(sd_group_level_sd_0_81, 2)`) within models fitted to samples from the large population effect standard deviation. The mean estimate of the group-level standard deviation of log(`\textit{k}`) was `r round(mean_group_level_sd_log_k, 2)` (`\textit{SD}` = `r round(sd_group_level_sd_log_k, 2)`).

```
\begin{figure} [H]
    \centering
    \caption{Group-level}
    \label{fig:values}
    \includegraphics[width=1\linewidth]{figures/recovery.pdf}
\end{figure}
```





-> Scatter Plot: y = SD estimates, x = SD true parameters (4800 Punkte, farblich, mit 45° Linie)

-> partial pooling stats and multiplot



-> table: true sample mean | group-level mean | mean subj-level estimate | Mean change
- 4 rows: log_k + s_log_k (3 effect SDs) ?? unnötig, weil keine Unterschiede





```
\begin{figure} [H]
    \centering
    \caption{Parameter recovery and partial pooling}
    \label{fig:recovery}
    \includegraphics[width=1\linewidth]{figures/multiplot_recovery.png}
    \caption*{Note. \textnormal{Recovery of subject-level parameters (A), mean estimates of the group-level mean (B), mean differences between the variance of true subject-level parameters and the variance of subject-level estimates within samples (C)}}
\end{figure}
```
<br>
`\subsection{Inference methods}`
Across all models, Savage-Dickey BFs ranged from `r round(min(df_results$savage_dickey_bf),2)` to `r round(max(df_results$savage_dickey_bf),2)` (`\textit{M}` = `r round(mean(df_results$savage_dickey_bf),2)`, `\textit{SD}` = `r round(sd(df_results$savage_dickey_bf),2)`), dBFs ranged from `r round(min(df_results$directional_bf),2)` to `r round(max(df_results$directional_bf),2)` (`\textit{M}` = `r round(mean(df_results$directional_bf),2)`, `\textit{SD}` = `r round(sd(df_results$directional_bf),2)`) and P(effect > 0) ranged from `r remove_leading_zero(round(min(df_results$p_effect),2))` to `r remove_leading_zero(round(max(df_results$p_effect),2))` (`\textit{M}` = `r remove_leading_zero(round(mean(df_results$p_effect),2))`, `\textit{SD}` = `r remove_leading_zero(round(sd(df_results$p_effect),2))`). See Figure `\ref{fig:values}` for the distributions of Savage-Dickey BFs, dBFs, and P(effect > 0) proportions.`\\`

```
\begin{figure} [H]
    \centering
    \caption{Distributions of Savage-Dickey BFs, dBFs and P(effect > 0) proportions}
    \label{fig:values}
    \includegraphics[width=1\linewidth]{figures/multiplot_values.pdf}
    \caption*{Note. \textnormal{Solid lines indicate mean values.}}
\end{figure}
```
<br>
`\subsection{False positive results}`  
With a decision threshold of 3, `r round(fp_savage_dickey_bf_3 * 100, 2)``\%` of Savage-Dickey BFs were false positive. With a decision threshold of 1/3 for a negative and 3 for a positive effect, `r round(fp_directional_bf_3 * 100, 2)``\%` of dBFs were false positive. With 1/10 and 10 as directional decision thresholds, `r round(fp_directional_bf_10 * 100, 2)``\%` of dBFs were false positive, with 1/30 and 30, `r round(fp_directional_bf_30 * 100, 2)``\%` and with 1/100 and 100, `r round(fp_directional_bf_100 * 100, 2)``\%`. With a 80`\%` HDI, `r round(fp_hdi_80 * 100, 2)``\%` of decisions were false positive, with a 90`\%` HDI, `r round(fp_hdi_90 * 100, 2)``\%`, with a 95`\%` HDI, `r round(fp_hdi_95 * 100, 2)``\%` and with a 99`\%` HDI, `r round(fp_hdi_99 * 100, 2)``\%`. With P(effect > 0) > .95 for a positive and P(effect > 0) < .05 for negative effect, `r round(fp_p_effect_95 * 100, 2)``\%` of P(effect > 0) proportions were false positive. With > .975 and < .025 as directional thresholds, `r round(fp_p_effect_975 * 100, 2)``\%` of P(effect > 0) proportions were false positive and with > .99 and < .01, `r round(fp_p_effect_99 * 100, 2)``\%`. See Figure `\ref{fig:fig_fp}` for the proportions of false positive results per prior and population effect standard deviations.`\\`

```
\begin{figure} [H]
    \centering
    \caption{Proportions of false positive results with conventional decision thresholds}
    \label{fig:fig_fp}
    \includegraphics[width=1\linewidth]{figures/multiplot_fp.pdf}
    \caption*{Note. \textnormal{Dashed lines indicate a proportion of 5\% false positive results.}}
\end{figure}
```
<br>
`\subsection{Simulation-based decision thresholds}`  
With a decision threshold of `r round(sim_based_thres$savage_dickey_bf[1],2)`, 5`\%` of Savage Dickey BFs were false positive. The dBF produced 5`\%` false positive results, with a decision threshold of `r round(sim_based_thres$directional_bf_upper[1],2)` for a positive and `r round(sim_based_thres$directional_bf_lower[1],2)` for a negative effect. A decision rule of P(effect > 0) > `r remove_leading_zero(round(sim_based_thres$p_effect_upper[1],2))` for a positive and P(effect > 0) < `r remove_leading_zero(round(sim_based_thres$p_effect_lower[1],2))` for a negative effect resulted in 5`\%` false positives. The HDI against zero decision rule produced 5`\%` false positive results with a `r round(sim_based_thres$hdi[1]*100,2)``\%` HDI. See Figure `\ref{fig:fp_sim}` for the proportions of false positive results per prior and population effect standard deviations. Simulation-based decision thresholds for single and multiple tests are shown in Figure `\ref{fig:thresholds}`.`\\`

```
\begin{figure} [H]
    \centering
    \caption{False positive results with simulation-based decision thresholds}
    \label{fig:fp_sim}
    \includegraphics[width=1\linewidth]{figures/multiplot_fp_sim.pdf}
\end{figure}
```
```
\begin{figure} [H]
    \centering
    \caption{Simulation-based decision thresholds for single and multiple tests}
    \label{fig:thresholds}
    \includegraphics[width=1\linewidth]{figures/multiplot_thresholds.pdf}
\end{figure}
```
<br>
`\subsubsection{Overlap of false positive results}`  
With simulation-based decision thresholds, `r round(ofp_savage_dickey_bf_directional_bf*100,2)``\%` of false positive Savage-Dickey BFs overlapped with false positive dBFs, `r round(ofp_savage_dickey_bf_hdi*100,2)``\%` overlapped with false positive HDI decisions and `r round(ofp_savage_dickey_bf_p_effect*100,2)``\%` overlapped with false positive P(effect > 0) proportions. `r round(ofp_directional_bf_hdi*100,2)``\%` of false positive dBFs overlapped with false positive HDI decisions and `r round(ofp_directional_bf_p_effect*100,2)``\%` overlapped with false positive P(effect > 0) proportions. `r round(ofp_hdi_p_effect*100,2)``\%` of false positive HDI decisions overlapped with false positive P(effect > 0) proportions.`\\`

`\subsubsection{Prior sensitivity}`  
Within samples, the mean range of Savage-Dickey BFs was `r round(mwsr_savage_dickey_bf,2)`, the mean range of dBFs was `r round(mwsr_directional_bf,2)`, and the mean range of P(effect > 0) proportions was `r round(mwsr_p_effect,2)`.  
`\\`  
With simulation-based decision thresholds, the Savage-Dickey BF came to diverging results due to different priors within `r round(ps_savage_dickey_bf_sim * 100, 2)``\%` of all samples. The dBF produced inconsistent results within `r round(ps_directional_bf_sim * 100, 2)``\%` of all samples. The HDI against zero decision rule came to different results within `r round(ps_hdi_sim * 100, 2)``\%` of all samples and P(effect > 0) came to diverging results within `r round(ps_p_effect_sim * 100, 2)``\%` of all samples. See Table `\ref{tab:prior_sensitivity}` for the prior sensitivities per population effect standard deviation.`\\`

```
\begin{table}[H]
    \caption{Prior sensitivity of each inference method per population effect SD}
    \label{tab:prior_sensitivity}
    \begin{tabularx}{\textwidth}{lXXX}
    \midrule
    \multicolumn{1}{c}{Inference method} & \multicolumn{3}{c}{Prior sensitivity per effect \textit{SD}}\\
    \cmidrule{2-4}
    \multicolumn{1}{c}{} & \multicolumn{1}{c}{0.2} & \multicolumn{1}{c}{0.51} & \multicolumn{1}{c}{0.81}\\
    \midrule
    Savage-Dickey $BF_{10}$ & \centering `r remove_leading_zero(round(ps_savage_dickey_bf_sim_0_2, 2))` & \centering `r remove_leading_zero(round(ps_savage_dickey_bf_sim_0_51, 2))` & \centering `r remove_leading_zero(round(ps_savage_dickey_bf_sim_0_81, 2))`\arraybackslash\\
    $dBF_{+-}$ & \centering `r remove_leading_zero(round(ps_directional_bf_sim_0_2, 2))` & \centering `r remove_leading_zero(round(ps_directional_bf_sim_0_51, 2))` & \centering `r remove_leading_zero(round(ps_directional_bf_sim_0_81, 2))`\arraybackslash\\
    95\% HDI & \centering `r remove_leading_zero(round(ps_hdi_sim_0_2, 2))` & \centering `r remove_leading_zero(round(ps_hdi_sim_0_51, 2))` & \centering `r remove_leading_zero(round(ps_hdi_sim_0_81, 2))`\arraybackslash\\
    P(effect > 0) & \centering `r remove_leading_zero(round(ps_p_effect_sim_0_2, 2))` & \centering `r remove_leading_zero(round(ps_p_effect_sim_0_51, 2))` & \centering `r remove_leading_zero(round(ps_p_effect_sim_0_81, 2))`\arraybackslash\\
    \midrule
    \end{tabularx}
\end{table}
```
<br>
